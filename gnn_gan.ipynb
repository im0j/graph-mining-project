{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e036aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "!export DGLBACKEND=pytorch\n",
    "import dgl\n",
    "import dgl.multiprocessing as mp\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5c4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "CUDA version: 10.2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = default_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1b5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf157c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'author': 2293783, 'paper': 449006},\n",
       "      num_edges={('author', 'writes', 'paper'): 1142106, ('paper', 'written-by', 'author'): 1142106},\n",
       "      metagraph=[('author', 'paper', 'writes'), ('paper', 'author', 'written-by')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('dataset/paper_author_relationship.bin'):\n",
    "    graph = dgl.load_graphs('dataset/paper_author_relationship.bin')[0][0]\n",
    "else:\n",
    "    data_authors, data_papers = [], []\n",
    "    with open('dataset/paper_author_relationship.csv') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            paper = i\n",
    "            authors = map(int, line.split(','))\n",
    "            for author in authors:\n",
    "                data_authors.append(author)\n",
    "                data_papers.append(paper)\n",
    "    graph = dgl.heterograph({\n",
    "        ('author', 'writes', 'paper'): (data_authors, data_papers),\n",
    "        ('paper', 'written-by', 'author'): (data_papers, data_authors)\n",
    "    }, device=device)\n",
    "    dgl.save_graphs('dataset/paper_author_relationship.bin', [graph])\n",
    "    del data_authors, data_papers\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afc7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    'dataset/train_dataset.csv',\n",
    "    header=0,\n",
    "    names=['source', 'target', 'label'],\n",
    "    dtype={'label': bool},\n",
    "    sep=',\\s+',\n",
    "    engine='python'\n",
    ")\n",
    "val = pd.read_csv(\n",
    "    'dataset/valid_dataset.csv',\n",
    "    header=0,\n",
    "    names=['source', 'target', 'label'],\n",
    "    dtype={'label': bool},\n",
    "    sep=',\\s+',\n",
    "    engine='python'\n",
    ")\n",
    "query = pd.read_csv(\n",
    "    'dataset/query_dataset.csv',\n",
    "    header=0,\n",
    "    names=['source', 'target'],\n",
    "    dtype={'label': bool},\n",
    "    sep=',\\s+',\n",
    "    engine='python'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a4aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, graph, in_features, hidden_features, out_features, rel_names):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        embed_dict = {\n",
    "            ntype: nn.Parameter(torch.Tensor(\n",
    "                graph.number_of_nodes(ntype), in_features))\n",
    "            for ntype in graph.ntypes\n",
    "        }\n",
    "\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(\n",
    "                embed, gain=nn.init.calculate_gain('leaky_relu', 0.05))\n",
    "\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_features, hidden_features)\n",
    "            for rel in rel_names\n",
    "        })\n",
    "\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hidden_features, out_features)\n",
    "            for rel in rel_names\n",
    "        })\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        x = F.leaky_relu(self.conv1(blocks[0], x), 0.05)\n",
    "        x = F.tanh(self.conv2(blocks[1], x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc8b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden_features)\n",
    "        self.linear2 = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.leaky_relu(self.linear1(z), 0.05)\n",
    "        z = F.leaky_relu(self.linear2(z), 0.05)\n",
    "        return z\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_features, hidden_features):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, hidden_features)\n",
    "        self.classifier = nn.Linear(hidden_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(0.05, self.linear(x))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce53ddac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "nids should be a dict of node type and ids for graph with multiple node types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3aa36a685395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/dgl/dataloading/pytorch/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, g, nids, block_sampler, device, use_ddp, ddp_seed, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0mblock_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_output_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_dgl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeCollator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcollator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_scalar_batcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_batcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_sampler\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0m_init_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ddp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddp_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, g, nids, block_sampler)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;34m\"nids should be a dict of node type and ids for graph with multiple node types\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: nids should be a dict of node type and ids for graph with multiple node types"
     ]
    }
   ],
   "source": [
    "node_features = 16\n",
    "hidden_features = 2 * node_features\n",
    "\n",
    "\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([\n",
    "    {('author', 'writes', 'paper'): 5},\n",
    "    {('paper', 'written-by', 'author'): 5},\n",
    "])\n",
    "dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    graph, graph.nodes['author'], sampler,\n",
    "    batch_size=1024, shuffle=True, drop_last=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model = GCN(node_features, hidden_features, node_features, graph.etypes).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "G = Generator(node_features, hidden_features, node_features).to(device)\n",
    "Du = Discriminator(node_features, hidden_features).to(device)\n",
    "Db = Discriminator(node_features, hidden_features).to(device)\n",
    "\n",
    "Lu = nn.BCEWithLogitsLoss().to(device)\n",
    "Lb = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=3e-4, betas=(0.5, 0.99))\n",
    "optimizer_Du = optim.Adam(Du.parameters(), lr=3e-4, betas=(0.5, 0.99))\n",
    "optimizer_Db = optim.Adam(Db.parameters(), lr=3e-4, betas=(0.5, 0.99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_nodes, output_nodes, blocks in dataloader:\n",
    "#     optimizer.zero_grad()\n",
    "#     blocks = [b.to(torch.device(device)) for b in blocks]\n",
    "#     input_features = blocks[0].srcdata['features']\n",
    "#     output_predictions = model(blocks, input_features)\n",
    "#     output_labels = blocks[-1].dstdata['label']\n",
    "#     loss = compute_loss(output_predictions, output_labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full on Python 3.6 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
